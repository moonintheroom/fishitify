import streamlit as st
from PIL import Image
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import cv2
import json

st.set_page_config(
    page_title="Fishitify",  # ì›¹ ë¸Œë¼ìš°ì € íƒ­ ì œëª©
    page_icon="ğŸŸ",         # íƒ­ ì•„ì´ì½˜ (ì´ëª¨ì§€ ë˜ëŠ” URL)
    layout="wide",      # í˜ì´ì§€ ë ˆì´ì•„ì›ƒ (centered, wide)
)

st.markdown(
    """
    <style>
    .centered-content {
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        text-align: center; /* í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬ */
        height: 50px; /* ë†’ì´ ì„¤ì • (ì¡°ì • ê°€ëŠ¥) */
    }
    .centered-content h1 {
        color: #79ABFF; /* h1 ìƒ‰ìƒ ì„¤ì • (íŒŒë€ìƒ‰) */
        font-size: 2.5rem; /* ê¸€ê¼´ í¬ê¸° ì¡°ì • */
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ì¤‘ì•™ ì •ë ¬ëœ ì½˜í…ì¸  í‘œì‹œ
st.markdown(
    """
    <div class="centered-content">
        <h1>Fishitify ë°©ë¬¸ì„ í™˜ì˜í•©ë‹ˆë‹¤ ğŸ³</h1>
        <h3>ì•Œê³  ì‹¶ì€ í•´ì–‘ìƒë¬¼ ì‚¬ì§„ì„ ì—…ë¡œë“œ í•˜ì—¬ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.</h3>
    </div>
    """,
    unsafe_allow_html=True
)
# í´ë˜ìŠ¤ ì´ë¦„ ë° ê³ ìœ  ìƒ‰ìƒ ì„¤ì •
class_names = [
    'bang-eo', 'daegu', 'gamseongdom',
    'gasung-eo', 'godeung-eo', 'hwang-eo',
    'nong-eo', 'sung-eo'
]
class_colors = {
    'bang-eo': (0, 0, 255),     # ë¹¨ê°„ìƒ‰
    'daegu': (0, 255, 0),       # ì´ˆë¡ìƒ‰
    'gamseongdom': (255, 0, 0), # íŒŒë€ìƒ‰
    'gasung-eo': (0, 255, 255), # ë…¸ë€ìƒ‰
    'godeung-eo': (255, 105, 180),# í•‘í¬ìƒ‰
    'hwang-eo': (255, 0, 255),  # ìì£¼ìƒ‰
    'nong-eo': (128, 0, 128),   # ë³´ë¼ìƒ‰
    'sung-eo': (0, 128, 255)    # ì£¼í™©ìƒ‰
}

# JSON íŒŒì¼ ë¡œë“œ
@st.cache_resource
def load_class_info(json_path):
    with open(json_path, "r") as f:
        return json.load(f)

class_info = load_class_info("fish_class_info.json")  # JSON íŒŒì¼ ê²½ë¡œ

# YOLO ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def load_yolo_model(model_path):
    return YOLO(model_path)

# ê°ì²´ íƒì§€ í•¨ìˆ˜
def detect_objects_yolo(model, image):
    if image.mode != "RGB":
        image = image.convert("RGB")
    image_array = np.array(image)
    results = model.predict(source=image_array, save=False)
    return results

# Bounding Boxë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ëŠ” í•¨ìˆ˜
def draw_boxes(image, results, class_names, class_colors):
    for result in results[0].boxes.data.tolist():  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        x_min, y_min, x_max, y_max, confidence, class_id = result
        class_name = class_names[int(class_id)]  # í´ë˜ìŠ¤ ì´ë¦„
        color = class_colors[class_name]  # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ

        # OpenCVê°€ ì‚¬ìš©í•˜ëŠ” BGR í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        color_bgr = (color[2], color[1], color[0])  # RGB -> BGR

        label = f"{class_name} ({confidence:.2f})"

        # Bounding Box ê·¸ë¦¬ê¸°
        cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), color_bgr, thickness=3)
        cv2.putText(image, label, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_bgr, 2)

    return image

def resize_with_aspect_ratio(image, target_width, target_height):
    """
    ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ë¥¼ ì§€ì •ëœ í¬ê¸°ì— ë§ê²Œ í™•ì¥í•˜ê±°ë‚˜ ì¶•ì†Œí•©ë‹ˆë‹¤.
    """
    # RGBA ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
    if image.shape[2] == 4:  # 4ì±„ë„ ì´ë¯¸ì§€ì¼ ê²½ìš°
        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)

    # ì›ë³¸ í¬ê¸°ì™€ ë¹„ìœ¨ ê³„ì‚°
    height, width, _ = image.shape
    aspect_ratio = width / height

    # ìƒˆ í¬ê¸° ê³„ì‚°
    if width / target_width > height / target_height:
        new_width = target_width
        new_height = int(new_width / aspect_ratio)
    else:
        new_height = target_height
        new_width = int(new_height * aspect_ratio)

    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)

    # ëª©í‘œ í¬ê¸°ì˜ ìº”ë²„ìŠ¤ ìƒì„± (í°ìƒ‰ ë°°ê²½)
    canvas = np.full((target_height, target_width, 3), 1500, dtype=np.uint8)

    # ì´ë¯¸ì§€ ì¤‘ì•™ ì •ë ¬
    x_offset = (target_width - new_width) // 2
    y_offset = (target_height - new_height) // 2
    canvas[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized_image

    return canvas

# ëª¨ë¸ ë¡œë“œ ì—¬ë¶€ í™•ì¸
if "model" not in st.session_state:
    model_path = "best.pt"
    
    if Path(model_path).exists():
        st.session_state.model = load_yolo_model(model_path)
    else:
        st.warning("ìœ íš¨í•œ YOLO ëª¨ë¸ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ëª¨ë¸ ë¡œë“œ í›„ ê°ì²´ íƒì§€ ê¸°ëŠ¥
if "model" in st.session_state:
    model = st.session_state.model

    # ì´ë¯¸ì§€ ì—…ë¡œë“œ
    st.markdown(
        """
        <style>
        div[data-testid="stFileUploader"] {
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 18px; /* ê¸€ì í¬ê¸° */
            max-width: 1000px; /* ìµœëŒ€ ë„ˆë¹„ ì„¤ì • */
            margin: 20px auto; /* ê°€ìš´ë° ì •ë ¬ ë° ê°„ê²© */
            padding: 10px;
            border: 2px dashed #6c757d; /* í…Œë‘ë¦¬ ìŠ¤íƒ€ì¼ */
            border-radius: 10px; /* ë‘¥ê·¼ ëª¨ì„œë¦¬ */
            background-color: #f8f9fa; /* ë°°ê²½ìƒ‰ */
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Streamlit ì—…ë¡œë” ì‚¬ìš©
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["png", "jpg", "jpeg"])

    if uploaded_file:
        image = Image.open(uploaded_file)

        # YOLO ëª¨ë¸ë¡œ ê°ì²´ íƒì§€
        results = detect_objects_yolo(model, image)

        # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± ë° ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ê°€
        result_image = np.array(image)
        result_image = draw_boxes(result_image, results, class_names, class_colors)

        # ê³ ì •ëœ í¬ê¸°ë¡œ ì´ë¯¸ì§€ ì¡°ì •
        max_width, max_height = 800, 600  # ì›í•˜ëŠ” ì¶œë ¥ í¬ê¸°
        result_image = resize_with_aspect_ratio(result_image, max_width, max_height)

        # ì™¼ìª½ ì¹¸ì— ì´ë¯¸ì§€ ì¤‘ì•™ ì •ë ¬
        col1, col2 = st.columns(2)
        with col1:
            # ë‚´ë¶€ì ìœ¼ë¡œ ì—´ì„ ì¶”ê°€í•´ ì¤‘ì•™ ì •ë ¬
            inner_col1, inner_col2, inner_col3 = st.columns([1, 2, 1])  # ì¤‘ì•™ ì—´ ë¹„ìœ¨ì„ í¬ê²Œ ì„¤ì •
            with inner_col2:
                st.image(result_image, caption="ê°ì²´ íƒì§€ ê²°ê³¼", use_container_width=False)

        # ì˜¤ë¥¸ìª½ ì¹¸ì— ì •ë³´ í‘œì‹œ
        with col2:
            st.subheader("ê°ì²´ íƒì§€ ì™„ë£Œ â—")

            # í‘œì‹œëœ í´ë˜ìŠ¤ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ì§‘í•© ìƒì„±
            displayed_classes = set()

            for result in results[0].boxes.data.tolist():
                x_min, y_min, x_max, y_max, confidence, class_id = result
                class_name = class_names[int(class_id)]

                # ì¤‘ë³µëœ í´ë˜ìŠ¤ëŠ” ê±´ë„ˆëœ€
                if class_name in displayed_classes:
                    continue

                displayed_classes.add(class_name)
                match_percentage = round(confidence * 100, 2)  # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼

                # í´ë˜ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                info = class_info.get(class_name, {})
                st.write(f"ğŸŸ **{info.get('name', class_name)}** ({match_percentage}% ì¼ì¹˜)")
                st.write(f"  - **ë¨¹ì„ ìˆ˜ ìˆë‚˜ìš”?**: {info.get('edible', 'ì •ë³´ ì—†ìŒ')}")
                st.write(f"  - **ì¢…ë¥˜**: {info.get('type', 'ì •ë³´ ì—†ìŒ')}")
                st.write(f"  - **ì„œì‹ì§€**: {info.get('habitat', 'ì •ë³´ ì—†ìŒ')}")
                st.write(f"  - **ì„¤ëª…**: {info.get('description', 'ì •ë³´ ì—†ìŒ')}")

else:
    st.warning("ë¨¼ì € YOLO ëª¨ë¸ì„ ë¡œë“œí•˜ì„¸ìš”.")